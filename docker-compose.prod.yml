services:
  # PostgreSQL Database - Production optimized
  db:
    image: postgres:15-alpine
    container_name: compatibility_db_prod
    environment:
      POSTGRES_DB: compatibility_system
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-strong_postgres_password_2024}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    networks:
      - compatibility_network
    restart: unless-stopped
    # Security and performance optimizations
    command: >
      postgres
      -c max_connections=100
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d compatibility_system"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache - Production optimized
  redis:
    image: redis:7-alpine
    container_name: compatibility_redis_prod
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - compatibility_network
    restart: unless-stopped
    # Redis configuration for production
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --timeout 300
      --tcp-keepalive 300
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Django Backend API - Production ready (Optimized for 1vCPU droplet)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: compatibility_backend_prod
    env_file:
      - .env.prod
    environment:
      - DEBUG=0
      - ALLOWED_HOSTS=localhost,127.0.0.1,${DOMAIN_NAME:-your-domain.com}
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD:-strong_postgres_password_2024}@db:5432/compatibility_system
      - REDIS_URL=redis://redis:6379/0
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY:-generate-a-strong-secret-key-for-production}
      - PYTHONUNBUFFERED=1
      - CELERY_BROKER_URL=redis://redis:6379/1
      - WEB_CONCURRENCY=1
      - GUNICORN_CMD_ARGS=--workers=1 --threads=2 --worker-connections=1000 --max-requests=1000 --max-requests-jitter=100 --timeout=30
    volumes:
      - static_files:/app/staticfiles
      - media_files:/app/media
      - logs:/app/logs
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - compatibility_network
    restart: unless-stopped
    # Resource limits for 1vCPU droplet
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 300M
        reservations:
          memory: 200M
    # Health check
    healthcheck:
      test: ["CMD", "python", "manage.py", "check"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Next.js Frontend - Production build
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
    container_name: compatibility_frontend_prod
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=${API_URL:-http://localhost:8000/api}
      - NEXT_TELEMETRY_DISABLED=1
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - compatibility_network
    restart: unless-stopped
    # Health check
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:3000",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

  # AI Scraping Service - Production ready
  scraper:
    build:
      context: ./scraper
      dockerfile: Dockerfile.prod
    container_name: compatibility_scraper_prod
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD:-strong_postgres_password_2024}@db:5432/compatibility_system
      - REDIS_URL=redis://redis:6379/1
      - SCRAPER_SCHEDULE=${SCRAPER_SCHEDULE:-0 2 * * *}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
    volumes:
      - scraper_logs:/app/logs
      - scraper_data:/app/data
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - compatibility_network
    restart: unless-stopped
    entrypoint: ["python", "main.py"]

  # Nginx Reverse Proxy - Production
  nginx:
    image: nginx:alpine
    container_name: compatibility_nginx_prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - static_files:/var/www/static:ro
      - media_files:/var/www/media:ro
      - ./certbot/conf:/etc/letsencrypt:ro
      - ./certbot/www:/var/www/certbot:ro
    depends_on:
      - backend
      - frontend
    networks:
      - compatibility_network
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Certbot for SSL certificates
  certbot:
    image: certbot/certbot
    container_name: compatibility_certbot_prod
    volumes:
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
      - ./certbot/scripts:/scripts:ro
    networks:
      - compatibility_network
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"
    restart: unless-stopped

  # Celery Worker for background tasks
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: compatibility_celery_worker
    environment:
      - DEBUG=0
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD:-strong_postgres_password_2024}@db:5432/compatibility_system
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/1
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY:-generate-a-strong-secret-key-for-production}
      - PYTHONUNBUFFERED=1
    volumes:
      - media_files:/app/media
      - logs:/app/logs
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - compatibility_network
    restart: unless-stopped
    # Resource limits for 1vCPU droplet
    deploy:
      resources:
        limits:
          cpus: "0.3"
          memory: 200M
        reservations:
          memory: 100M
    command: celery -A compatibility_system worker -l info --concurrency=1

  # Celery Beat for scheduled tasks
  celery_beat:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: compatibility_celery_beat
    environment:
      - DEBUG=0
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD:-strong_postgres_password_2024}@db:5432/compatibility_system
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/1
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY:-generate-a-strong-secret-key-for-production}
      - PYTHONUNBUFFERED=1
    volumes:
      - logs:/app/logs
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - compatibility_network
    restart: unless-stopped
    # Resource limits for 1vCPU droplet
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: 100M
        reservations:
          memory: 50M
    command: celery -A compatibility_system beat -l info

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  static_files:
    driver: local
  media_files:
    driver: local
  certbot_certs:
    driver: local
  certbot_www:
    driver: local
  scraper_logs:
    driver: local
  scraper_data:
    driver: local
  logs:
    driver: local

networks:
  compatibility_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
